v1:
  model_path: "meta-llama/Llama-3.2-1B-Instruct"
  model_name: "Llama-3.2-1B-Instruct"  # Model name for output file
  is_local_model: False
  batch_size: 32
  tensor_parallel_size: 2
  languages:
    - "en"
    - "kk"
    - "ru"
  benchmarks:
    - "mmlu"
    - "arc"
    - "winogrande"
    - "hellaswag"
  gpu_memory_utilization: 0.6
  datasets_dir: data/benchmark/datasets_v1

v2:
  model_path: "meta-llama/Llama-3.2-1B-Instruct"
  model_name: "Llama-3.2-1B-Instruct"
  benchmarks:
    - "gsm8k"
    - "arc"
    - "mmlu"
    - "drop"
    - "hellaswag"
    - "humaneval"
    - "winogrande"
  languages:
    - "kk"
    - "ru"
    - "en"
  batch_size: 64
  tensor_parallel_size: 8
  data_portion: 100
  max_tokens:
    mmlu: 15
    arc: 30
    drop: 40
    gsm8k: 512
    humaneval: 512
    hellaswag: 15
    winogrande: 15
  is_local: False
  datasets_dir: data/benchmark/datasets_v2
